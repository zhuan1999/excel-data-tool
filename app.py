import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from functools import lru_cache
import warnings
warnings.filterwarnings('ignore')

# ============================================
# å…¨å±€é…ç½®å’Œç¼“å­˜
# ============================================
st.set_page_config(
    page_title="Excelæ•°æ®å¤„ç†å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSä¼˜åŒ–åŠ è½½é€Ÿåº¦
st.markdown("""
<style>
    /* å‡å°‘é¡µé¢é‡ç»˜ */
    .stApp {
        contain: content;
        will-change: transform;
    }
    
    /* ä¼˜åŒ–è¡¨æ ¼æ¸²æŸ“ */
    .stDataFrame {
        will-change: transform;
    }
    
    /* åŠ è½½åŠ¨ç”» */
    .loading-spinner {
        display: none;
    }
    
    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .stButton > button {
        transition: all 0.2s ease;
    }
    
    /* ç¼“å­˜çŠ¶æ€æç¤º */
    .cache-status {
        font-size: 0.8rem;
        color: #666;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session stateç”¨äºæ¨¡å—é—´æ•°æ®ä¼ é€’
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'data_pipeline' not in st.session_state:
    st.session_state.data_pipeline = {}

# ç¼“å­˜è£…é¥°å™¨ - æ˜¾è‘—æå‡æ•°æ®å¤„ç†é€Ÿåº¦
@lru_cache(maxsize=5)
def cached_read_excel(file_bytes, file_name):
    """ç¼“å­˜è¯»å–Excelæ–‡ä»¶ï¼Œé¿å…é‡å¤è¯»å–"""
    try:
        if file_name.endswith('.csv'):
            df = pd.read_csv(BytesIO(file_bytes))
        else:
            df = pd.read_excel(BytesIO(file_bytes))
        return df
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def convert_column_types(df):
    """æ™ºèƒ½è½¬æ¢åˆ—ç±»å‹ï¼Œè§£å†³æ—¥æœŸå’Œæ•°å­—ç±»å‹é—®é¢˜"""
    for col in df.columns:
        # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸ
        try:
            if df[col].dtype == 'object':
                # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                date_col = pd.to_datetime(df[col], errors='coerce', infer_datetime_format=True)
                if date_col.notna().sum() > 0:  # å¦‚æœæœ‰æœ‰æ•ˆçš„æ—¥æœŸ
                    df[col] = date_col
        except:
            pass
        
        # å°è¯•è½¬æ¢ä¸ºæ•°å­—
        try:
            if df[col].dtype == 'object':
                numeric_col = pd.to_numeric(df[col], errors='coerce')
                if numeric_col.notna().sum() > len(df) * 0.5:  # å¦‚æœè¶…è¿‡50%æ˜¯æ•°å­—
                    df[col] = numeric_col
        except:
            pass
    
    return df

# ============================================
# ä¾§è¾¹æ  - æ•°æ®ç®¡é“ç®¡ç†
# ============================================
with st.sidebar:
    st.title("ğŸ“ æ•°æ®ç®¡é“ç®¡ç†")
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®ç®¡é“çŠ¶æ€
    if st.session_state.data_pipeline:
        st.markdown("### å½“å‰ç®¡é“æ•°æ®")
        for name, data_info in st.session_state.data_pipeline.items():
            with st.expander(f"ğŸ“„ {name}", expanded=False):
                st.write(f"å½¢çŠ¶: {data_info['shape']}")
                st.write(f"å†…å­˜: {data_info['memory_mb']:.2f} MB")
                st.write(f"æ›´æ–°æ—¶é—´: {data_info['timestamp'].strftime('%H:%M:%S')}")
                
                if st.button(f"åŠ è½½åˆ°å½“å‰æ¨¡å—", key=f"load_{name}"):
                    st.session_state.processed_data = data_info['data'].copy()
                    st.success(f"å·²åŠ è½½ {name} åˆ°å½“å‰æ¨¡å—")
                    st.rerun()
    else:
        st.info("æš‚æ— ç®¡é“æ•°æ®")
    
    st.markdown("---")
    st.markdown("### ğŸš€ æ€§èƒ½ä¼˜åŒ–")
    
    # æ€§èƒ½è®¾ç½®
    use_cache = st.checkbox("å¯ç”¨æ•°æ®ç¼“å­˜", value=True)
    optimize_memory = st.checkbox("å¯ç”¨å†…å­˜ä¼˜åŒ–", value=True)
    
    if st.button("ğŸ”„ æ¸…ç†ç¼“å­˜"):
        cached_read_excel.cache_clear()
        st.success("ç¼“å­˜å·²æ¸…ç†")
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    st.info("""
    **å·¥ä½œæµç¨‹ï¼š**
    1. æ¯ä¸ªæ¨¡å—å¤„ç†çš„æ•°æ®ä¼šè‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®ç®¡é“
    2. å¯ä»¥ä»ä¾§è¾¹æ åŠ è½½ä¹‹å‰å¤„ç†çš„æ•°æ®
    3. æ”¯æŒæ¨¡å—é—´çš„æ•°æ®ä¼ é€’
    4. è‡ªåŠ¨å¤„ç†æ•°æ®ç±»å‹åŒ¹é…é—®é¢˜
    """)

# ============================================
# ä¸»åº”ç”¨æ ‡é¢˜
# ============================================
st.title("ğŸš€ Excelæ•°æ®å¤„ç†å·¥å…· (ä¼˜åŒ–ç‰ˆ)")

# ============================================
# æ•°æ®åˆå¹¶æ¨¡å— - ä¿®å¤æ—¥æœŸå­—æ®µé—®é¢˜
# ============================================
st.header("ğŸ“¥ æ•°æ®åˆå¹¶æ¨¡å—")

# å¿«é€Ÿæ“ä½œæ 
col1, col2, col3 = st.columns(3)
with col1:
    load_from_pipeline = st.checkbox("ä»ç®¡é“åŠ è½½æ•°æ®", key="merge_load_pipeline")
with col2:
    clear_cache = st.button("ğŸ”„ åˆ·æ–°è§†å›¾")
with col3:
    if st.button("ğŸ’¾ ä¿å­˜åˆ°ç®¡é“", key="merge_save"):
        if 'merged_df' in locals():
            st.session_state.data_pipeline['åˆå¹¶ç»“æœ'] = {
                'data': merged_df,
                'shape': merged_df.shape,
                'memory_mb': merged_df.memory_usage(deep=True).sum() / 1024 / 1024,
                'timestamp': pd.Timestamp.now()
            }
            st.success("å·²ä¿å­˜åˆ°æ•°æ®ç®¡é“")

if load_from_pipeline and st.session_state.data_pipeline:
    selected_data = st.selectbox("é€‰æ‹©ç®¡é“æ•°æ®", list(st.session_state.data_pipeline.keys()))
    if selected_data:
        merged_df = st.session_state.data_pipeline[selected_data]['data'].copy()
        st.success(f"å·²åŠ è½½ {selected_data}")
else:
    col1, col2 = st.columns(2)
    
    with col1:
        file1 = st.file_uploader("é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶", type=['xlsx', 'xls', 'csv'], key="merge_file1")
        if file1:
            with st.spinner("å¿«é€Ÿè¯»å–ä¸­..."):
                # ä½¿ç”¨ç¼“å­˜è¯»å–
                df1 = cached_read_excel(file1.getvalue(), file1.name)
                if df1 is not None:
                    df1 = convert_column_types(df1)  # è½¬æ¢æ•°æ®ç±»å‹
                    st.success(f"âœ… {file1.name} - {df1.shape[0]}è¡ŒÃ—{df1.shape[1]}åˆ—")
                    
                    # æ˜¾ç¤ºæ•°æ®ç±»å‹ä¿¡æ¯
                    date_cols = [col for col in df1.columns if pd.api.types.is_datetime64_any_dtype(df1[col])]
                    if date_cols:
                        st.info(f"ğŸ“… æ£€æµ‹åˆ°æ—¥æœŸå­—æ®µ: {', '.join(date_cols)}")
    
    with col2:
        file2 = st.file_uploader("é€‰æ‹©ç¬¬äºŒä¸ªæ–‡ä»¶", type=['xlsx', 'xls', 'csv'], key="merge_file2")
        if file2:
            with st.spinner("å¿«é€Ÿè¯»å–ä¸­..."):
                df2 = cached_read_excel(file2.getvalue(), file2.name)
                if df2 is not None:
                    df2 = convert_column_types(df2)  # è½¬æ¢æ•°æ®ç±»å‹
                    st.success(f"âœ… {file2.name} - {df2.shape[0]}è¡ŒÃ—{df2.shape[1]}åˆ—")

if 'df1' in locals() and 'df2' in locals():
    st.markdown("### åˆå¹¶è®¾ç½®")
    
    merge_method = st.radio(
        "é€‰æ‹©åˆå¹¶æ–¹å¼",
        ["å‚ç›´åˆå¹¶ï¼ˆè¿½åŠ è¡Œï¼‰", "æ°´å¹³åˆå¹¶ï¼ˆè¿æ¥åˆ—ï¼‰", "ä¸»é”®åˆå¹¶ï¼ˆç±»ä¼¼SQL JOINï¼‰"],
        horizontal=True
    )
    
    if merge_method == "ä¸»é”®åˆå¹¶ï¼ˆç±»ä¼¼SQL JOINï¼‰":
        # æ™ºèƒ½è¯†åˆ«å…±åŒåˆ—
        common_cols = list(set(df1.columns) & set(df2.columns))
        if common_cols:
            col1, col2 = st.columns(2)
            with col1:
                merge_on = st.selectbox("é€‰æ‹©ä¸»é”®åˆ—", common_cols)
            with col2:
                merge_how = st.selectbox("åˆå¹¶æ–¹å¼", ["inner", "left", "right", "outer"])
        else:
            st.warning("âš ï¸ æœªæ‰¾åˆ°å…±åŒåˆ—")
    
    if st.button("ğŸš€ å¿«é€Ÿåˆå¹¶", type="primary", use_container_width=True):
        with st.spinner("æ­£åœ¨åˆå¹¶æ•°æ®..."):
            try:
                if merge_method == "å‚ç›´åˆå¹¶ï¼ˆè¿½åŠ è¡Œï¼‰":
                    # å¯¹é½åˆ—åï¼Œç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
                    all_columns = list(set(df1.columns) | set(df2.columns))
                    df1_aligned = df1.reindex(columns=all_columns)
                    df2_aligned = df2.reindex(columns=all_columns)
                    merged_df = pd.concat([df1_aligned, df2_aligned], ignore_index=True)
                    
                elif merge_method == "æ°´å¹³åˆå¹¶ï¼ˆè¿æ¥åˆ—ï¼‰":
                    merged_df = pd.concat([df1, df2], axis=1)
                    
                elif merge_method == "ä¸»é”®åˆå¹¶ï¼ˆç±»ä¼¼SQL JOINï¼‰":
                    # ç¡®ä¿ä¸»é”®åˆ—ç±»å‹ä¸€è‡´
                    if merge_on in df1.columns and merge_on in df2.columns:
                        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹é¿å…åŒ¹é…é”™è¯¯
                        df1[merge_on] = df1[merge_on].astype(str).str.strip()
                        df2[merge_on] = df2[merge_on].astype(str).str.strip()
                        merged_df = pd.merge(df1, df2, on=merge_on, how=merge_how, suffixes=('_è¡¨1', '_è¡¨2'))
                
                # å¤„ç†æ—¥æœŸå­—æ®µ - ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                for col in merged_df.columns:
                    if merged_df[col].dtype == 'object':
                        # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸ
                        try:
                            date_series = pd.to_datetime(merged_df[col], errors='ignore')
                            if date_series.dtype != 'object':  # å¦‚æœè½¬æ¢æˆåŠŸ
                                merged_df[col] = date_series
                        except:
                            pass
                
                st.success(f"âœ… åˆå¹¶å®Œæˆï¼å…± {merged_df.shape[0]} è¡Œ Ã— {merged_df.shape[1]} åˆ—")
                
                # ä¿å­˜åˆ°session state
                st.session_state.processed_data = merged_df.copy()
                
                # æ˜¾ç¤ºç»“æœ
                with st.expander("ğŸ“Š æŸ¥çœ‹åˆå¹¶ç»“æœ", expanded=True):
                    st.dataframe(merged_df.head(50), use_container_width=True)
                    
                    # æ•°æ®ç»Ÿè®¡
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»è¡Œæ•°", merged_df.shape[0])
                    with col2:
                        st.metric("æ€»åˆ—æ•°", merged_df.shape[1])
                    with col3:
                        missing_total = merged_df.isnull().sum().sum()
                        st.metric("ç¼ºå¤±å€¼", missing_total)
                
                # ä¸‹è½½æŒ‰é’®
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    merged_df.to_excel(writer, index=False, sheet_name='åˆå¹¶æ•°æ®')
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆå¹¶ç»“æœ",
                    data=output.getvalue(),
                    file_name="åˆå¹¶æ•°æ®.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
                
                # è‡ªåŠ¨ä¿å­˜åˆ°ç®¡é“
                st.session_state.data_pipeline['åˆå¹¶ç»“æœ'] = {
                    'data': merged_df,
                    'shape': merged_df.shape,
                    'memory_mb': merged_df.memory_usage(deep=True).sum() / 1024 / 1024,
                    'timestamp': pd.Timestamp.now()
                }
                
            except Exception as e:
                st.error(f"âŒ åˆå¹¶é”™è¯¯: {str(e)}")
                st.code(f"é”™è¯¯è¯¦æƒ…: {e.__class__.__name__}")

# ============================================
# æ•°æ®åŒ¹é…æ¨¡å— - ä¿®å¤ç±»å‹åŒ¹é…é—®é¢˜
# ============================================
st.header("ğŸ”„ æ•°æ®åŒ¹é…æ¨¡å—")

# å¿«é€Ÿé€‰æ‹©æ•°æ®æº
data_source_option = st.radio(
    "é€‰æ‹©æ•°æ®æº",
    ["ä»ç®¡é“åŠ è½½æ•°æ®", "ä¸Šä¼ æ–°æ–‡ä»¶"],
    horizontal=True,
    key="match_source"
)

if data_source_option == "ä»ç®¡é“åŠ è½½æ•°æ®" and st.session_state.data_pipeline:
    # é€‰æ‹©ç®¡é“æ•°æ®
    pipeline_options = list(st.session_state.data_pipeline.keys())
    selected_main = st.selectbox("é€‰æ‹©ä¸»è¡¨æ•°æ®", pipeline_options, key="main_from_pipe")
    selected_lookup = st.selectbox("é€‰æ‹©åŒ¹é…è¡¨æ•°æ®", pipeline_options, key="lookup_from_pipe")
    
    if selected_main and selected_lookup:
        main_df = st.session_state.data_pipeline[selected_main]['data'].copy()
        lookup_df = st.session_state.data_pipeline[selected_lookup]['data'].copy()
        st.success(f"âœ… å·²åŠ è½½: ä¸»è¡¨({selected_main}), åŒ¹é…è¡¨({selected_lookup})")
else:
    # ä¼ ç»Ÿæ–‡ä»¶ä¸Šä¼ 
    col1, col2 = st.columns(2)
    
    with col1:
        main_file = st.file_uploader("ä¸Šä¼ ä¸»è¡¨", type=['xlsx', 'xls', 'csv'], key="match_main")
        if main_file:
            with st.spinner("åŠ è½½ä¸»è¡¨..."):
                main_df = cached_read_excel(main_file.getvalue(), main_file.name)
                if main_df is not None:
                    main_df = convert_column_types(main_df)
                    st.success(f"âœ… {main_file.name} - {main_df.shape[0]}è¡Œ")
    
    with col2:
        lookup_file = st.file_uploader("ä¸Šä¼ åŒ¹é…è¡¨", type=['xlsx', 'xls', 'csv'], key="match_lookup")
        if lookup_file:
            with st.spinner("åŠ è½½åŒ¹é…è¡¨..."):
                lookup_df = cached_read_excel(lookup_file.getvalue(), lookup_file.name)
                if lookup_df is not None:
                    lookup_df = convert_column_types(lookup_df)
                    st.success(f"âœ… {lookup_file.name} - {lookup_df.shape[0]}è¡Œ")

if 'main_df' in locals() and 'lookup_df' in locals():
    st.markdown("### ğŸ” åŒ¹é…è®¾ç½®")
    
    # å¿«é€Ÿå­—æ®µé€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        main_columns = list(main_df.columns)
        main_key = st.selectbox(
            "é€‰æ‹©ä¸»è¡¨åŒ¹é…å­—æ®µ",
            main_columns,
            help="ç”¨äºåŒ¹é…çš„å…³é”®å­—æ®µ",
            key="main_key_select"
        )
        
        # æ˜¾ç¤ºå­—æ®µä¿¡æ¯
        if main_key:
            dtype_main = str(main_df[main_key].dtype)
            unique_count = main_df[main_key].nunique()
            st.caption(f"ç±»å‹: {dtype_main} | å”¯ä¸€å€¼: {unique_count}")
    
    with col2:
        lookup_columns = list(lookup_df.columns)
        lookup_key = st.selectbox(
            "é€‰æ‹©åŒ¹é…è¡¨å¯¹åº”å­—æ®µ",
            lookup_columns,
            help="åŒ¹é…è¡¨ä¸­å¯¹åº”çš„å…³é”®å­—æ®µ",
            key="lookup_key_select"
        )
        
        if lookup_key:
            dtype_lookup = str(lookup_df[lookup_key].dtype)
            unique_count = lookup_df[lookup_key].nunique()
            st.caption(f"ç±»å‹: {dtype_lookup} | å”¯ä¸€å€¼: {unique_count}")
    
    # ç±»å‹å…¼å®¹æ€§æ£€æŸ¥
    if 'main_key' in locals() and 'lookup_key' in locals():
        # è‡ªåŠ¨æ£€æµ‹ç±»å‹æ˜¯å¦éœ€è¦è½¬æ¢
        if main_df[main_key].dtype != lookup_df[lookup_key].dtype:
            st.warning(f"âš ï¸ å­—æ®µç±»å‹ä¸åŒ¹é…: ä¸»è¡¨({main_df[main_key].dtype}) vs åŒ¹é…è¡¨({lookup_df[lookup_key].dtype})")
            
            # è‡ªåŠ¨è½¬æ¢é€‰é¡¹
            auto_fix = st.checkbox("ğŸ”„ è‡ªåŠ¨è½¬æ¢ç±»å‹ä¸ºå­—ç¬¦ä¸²", value=True)
            if auto_fix:
                with st.spinner("æ­£åœ¨æ ‡å‡†åŒ–å­—æ®µç±»å‹..."):
                    main_df[main_key] = main_df[main_key].astype(str).str.strip()
                    lookup_df[lookup_key] = lookup_df[lookup_key].astype(str).str.strip()
                st.success("âœ… å­—æ®µç±»å‹å·²ç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²")
    
    # é€‰æ‹©è¦åŒ¹é…çš„å­—æ®µ
    available_fields = [col for col in lookup_df.columns if col != lookup_key]
    if available_fields:
        selected_fields = st.multiselect(
            "é€‰æ‹©è¦åŒ¹é…çš„å­—æ®µ",
            available_fields,
            help="é€‰æ‹©éœ€è¦ä»åŒ¹é…è¡¨æ·»åŠ åˆ°ä¸»è¡¨çš„å­—æ®µ"
        )
        
        if selected_fields:
            # å¿«é€Ÿæ±‡æ€»æ–¹å¼é€‰æ‹©
            st.markdown("### âš™ï¸ æ±‡æ€»è®¾ç½®")
            
            # æ‰¹é‡è®¾ç½®ç›¸åŒæ±‡æ€»æ–¹å¼
            col1, col2 = st.columns([2, 1])
            with col1:
                batch_agg = st.selectbox(
                    "æ‰¹é‡è®¾ç½®æ±‡æ€»æ–¹å¼",
                    ["ç¬¬ä¸€ä¸ªå€¼", "æ±‚å’Œ", "å¹³å‡å€¼", "æœ€å¤§å€¼", "æœ€å°å€¼", "è®¡æ•°"],
                    help="ä¸ºæ‰€æœ‰é€‰ä¸­å­—æ®µè®¾ç½®ç›¸åŒçš„æ±‡æ€»æ–¹å¼"
                )
            
            with col2:
                if st.button("åº”ç”¨æ‰¹é‡è®¾ç½®", use_container_width=True):
                    st.success(f"å·²ä¸ºæ‰€æœ‰å­—æ®µåº”ç”¨'{batch_agg}'")
            
            # æ˜¾ç¤ºå­—æ®µè®¾ç½®
            field_settings = {}
            for field in selected_fields:
                with st.expander(f"å­—æ®µ: {field}", expanded=False):
                    col1, col2 = st.columns(2)
                    with col1:
                        if lookup_df[field].dtype in ['int64', 'float64', 'Int64', 'Float64']:
                            agg_options = ["ç¬¬ä¸€ä¸ªå€¼", "æ±‚å’Œ", "å¹³å‡å€¼", "æœ€å¤§å€¼", "æœ€å°å€¼", "è®¡æ•°"]
                            default_idx = agg_options.index(batch_agg) if batch_agg in agg_options else 0
                        else:
                            agg_options = ["ç¬¬ä¸€ä¸ªå€¼", "è®¡æ•°", "è¿æ¥(é€—å·åˆ†éš”)"]
                            default_idx = agg_options.index(batch_agg) if batch_agg in agg_options else 0
                        
                        agg_method = st.selectbox(
                            "æ±‡æ€»æ–¹å¼",
                            agg_options,
                            index=default_idx,
                            key=f"agg_{field}"
                        )
                    
                    with col2:
                        new_name = st.text_input(
                            "æ–°åˆ—å",
                            value=f"åŒ¹é…_{field}",
                            key=f"name_{field}"
                        )
                    
                    field_settings[field] = {
                        'agg': agg_method,
                        'new_name': new_name
                    }
            
            # æ‰§è¡ŒåŒ¹é…
            if st.button("ğŸš€ æ‰§è¡Œæ™ºèƒ½åŒ¹é…", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡ŒåŒ¹é…..."):
                    try:
                        # åˆ›å»ºç»“æœæ•°æ®æ¡†
                        result_df = main_df.copy()
                        
                        # å¤„ç†æ¯ä¸ªå­—æ®µ
                        for field, settings in field_settings.items():
                            agg_method = settings['agg']
                            new_col_name = settings['new_name']
                            
                            # å‡†å¤‡åŒ¹é…æ•°æ®
                            temp_lookup = lookup_df[[lookup_key, field]].copy()
                            
                            # å¤„ç†é‡å¤é”®
                            if agg_method == "ç¬¬ä¸€ä¸ªå€¼":
                                temp_lookup = temp_lookup.drop_duplicates(subset=[lookup_key], keep='first')
                            elif agg_method == "æ±‚å’Œ":
                                temp_lookup = temp_lookup.groupby(lookup_key)[field].sum().reset_index()
                            elif agg_method == "å¹³å‡å€¼":
                                temp_lookup = temp_lookup.groupby(lookup_key)[field].mean().reset_index()
                            elif agg_method == "æœ€å¤§å€¼":
                                temp_lookup = temp_lookup.groupby(lookup_key)[field].max().resetindex()
                            elif agg_method == "æœ€å°å€¼":
                                temp_lookup = temp_lookup.groupby(lookup_key)[field].min().reset_index()
                            elif agg_method == "è®¡æ•°":
                                temp_lookup = temp_lookup.groupby(lookup_key)[field].count().reset_index()
                            elif agg_method == "è¿æ¥(é€—å·åˆ†éš”)":
                                temp_lookup = temp_lookup.groupby(lookup_key)[field].apply(
                                    lambda x: ', '.join([str(i) for i in x if pd.notna(i)])
                                ).reset_index()
                            
                            # ç¡®ä¿å­—æ®µç±»å‹ä¸€è‡´
                            result_df[main_key] = result_df[main_key].astype(str).str.strip()
                            temp_lookup[lookup_key] = temp_lookup[lookup_key].astype(str).str.strip()
                            
                            # æ‰§è¡ŒåŒ¹é…
                            result_df = result_df.merge(
                                temp_lookup,
                                how='left',
                                left_on=main_key,
                                right_on=lookup_key,
                                suffixes=('', '_match')
                            )
                            
                            # é‡å‘½ååŒ¹é…çš„åˆ—
                            if field in result_df.columns:
                                result_df = result_df.rename(columns={field: new_col_name})
                        
                        # æ¸…ç†å¤šä½™çš„åˆ—
                        if lookup_key in result_df.columns and lookup_key != main_key:
                            result_df = result_df.drop(columns=[lookup_key])
                        
                        # å»é‡
                        result_df = result_df.loc[:, ~result_df.columns.duplicated()]
                        
                        st.success(f"âœ… åŒ¹é…å®Œæˆï¼å…± {result_df.shape[0]} è¡Œ Ã— {result_df.shape[1]} åˆ—")
                        
                        # æ˜¾ç¤ºç»“æœ
                        with st.expander("ğŸ“Š æŸ¥çœ‹åŒ¹é…ç»“æœ", expanded=True):
                            st.dataframe(result_df.head(50), use_container_width=True)
                            
                            # åŒ¹é…ç»Ÿè®¡
                            matched_cols = [settings['new_name'] for settings in field_settings.values()]
                            if matched_cols:
                                matched_count = result_df[matched_cols].notna().any(axis=1).sum()
                                match_rate = (matched_count / len(result_df)) * 100
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("åŒ¹é…æˆåŠŸè¡Œæ•°", matched_count)
                                with col2:
                                    st.metric("åŒ¹é…æˆåŠŸç‡", f"{match_rate:.1f}%")
                        
                        # ä¸‹è½½ç»“æœ
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            result_df.to_excel(writer, index=False, sheet_name='åŒ¹é…ç»“æœ')
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½åŒ¹é…ç»“æœ",
                            data=output.getvalue(),
                            file_name="åŒ¹é…ç»“æœ.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                        
                        # ä¿å­˜åˆ°ç®¡é“
                        st.session_state.processed_data = result_df.copy()
                        st.session_state.data_pipeline['åŒ¹é…ç»“æœ'] = {
                            'data': result_df,
                            'shape': result_df.shape,
                            'memory_mb': result_df.memory_usage(deep=True).sum() / 1024 / 1024,
                            'timestamp': pd.Timestamp.now()
                        }
                        
                    except Exception as e:
                        st.error(f"âŒ åŒ¹é…é”™è¯¯: {str(e)}")
                        st.code(f"é”™è¯¯è¯¦æƒ…:\n{e.__class__.__name__}: {str(e)}")
    else:
        st.warning("åŒ¹é…è¡¨ä¸­æ²¡æœ‰å…¶ä»–å¯åŒ¹é…çš„å­—æ®µ")

# ============================================
# æ•°æ®æ¸…æ´—æ¨¡å—
# ============================================
st.header("ğŸ§¹ æ•°æ®æ¸…æ´—æ¨¡å—")

# æ•°æ®æºé€‰æ‹©
clean_source = st.radio(
    "é€‰æ‹©æ¸…æ´—æ•°æ®æº",
    ["ä»ç®¡é“åŠ è½½æ•°æ®", "ä¸Šä¼ æ–°æ–‡ä»¶", "ä½¿ç”¨ä¸Šä¸€ä¸ªæ¨¡å—ç»“æœ"],
    horizontal=True,
    key="clean_source"
)

if clean_source == "ä»ç®¡é“åŠ è½½æ•°æ®" and st.session_state.data_pipeline:
    pipeline_options = list(st.session_state.data_pipeline.keys())
    selected_clean = st.selectbox("é€‰æ‹©è¦æ¸…æ´—çš„æ•°æ®", pipeline_options, key="clean_from_pipe")
    if selected_clean:
        clean_df = st.session_state.data_pipeline[selected_clean]['data'].copy()
        st.success(f"âœ… å·²åŠ è½½: {selected_clean}")
elif clean_source == "ä½¿ç”¨ä¸Šä¸€ä¸ªæ¨¡å—ç»“æœ" and st.session_state.processed_data is not None:
    clean_df = st.session_state.processed_data.copy()
    st.success("âœ… å·²åŠ è½½ä¸Šä¸€ä¸ªæ¨¡å—çš„ç»“æœ")
else:
    clean_file = st.file_uploader("ä¸Šä¼ è¦æ¸…æ´—çš„æ–‡ä»¶", type=['xlsx', 'xls', 'csv'], key="clean_file")
    if clean_file:
        with st.spinner("å¿«é€ŸåŠ è½½ä¸­..."):
            clean_df = cached_read_excel(clean_file.getvalue(), clean_file.name)
            if clean_df is not None:
                clean_df = convert_column_types(clean_df)
                st.success(f"âœ… {clean_file.name} - {clean_df.shape[0]}è¡ŒÃ—{clean_df.shape[1]}åˆ—")

if 'clean_df' in locals():
    st.markdown("### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    
    # å¿«é€Ÿç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»è¡Œæ•°", clean_df.shape[0])
    with col2:
        st.metric("æ€»åˆ—æ•°", clean_df.shape[1])
    with col3:
        missing_total = clean_df.isnull().sum().sum()
        st.metric("ç¼ºå¤±å€¼", missing_total)
    with col4:
        dup_rows = clean_df.duplicated().sum()
        st.metric("é‡å¤è¡Œ", dup_rows)
    
    # å¿«é€Ÿæ¸…æ´—æ“ä½œ
    st.markdown("### âš¡ å¿«é€Ÿæ¸…æ´—æ“ä½œ")
    
    quick_ops = st.columns(5)
    
    with quick_ops[0]:
        if st.button("åˆ é™¤é‡å¤è¡Œ", use_container_width=True):
            original_len = len(clean_df)
            clean_df = clean_df.drop_duplicates()
            removed = original_len - len(clean_df)
            st.success(f"âœ… å·²åˆ é™¤ {removed} è¡Œé‡å¤æ•°æ®")
            st.rerun()
    
    with quick_ops[1]:
        if st.button("åˆ é™¤ç©ºå€¼è¡Œ", use_container_width=True):
            original_len = len(clean_df)
            clean_df = clean_df.dropna()
            removed = original_len - len(clean_df)
            st.success(f"âœ… å·²åˆ é™¤ {removed} è¡Œç©ºå€¼æ•°æ®")
            st.rerun()
    
    with quick_ops[2]:
        if st.button("é‡ç½®ç´¢å¼•", use_container_width=True):
            clean_df = clean_df.reset_index(drop=True)
            st.success("âœ… ç´¢å¼•å·²é‡ç½®")
            st.rerun()
    
    with quick_ops[3]:
        if st.button("æ ‡å‡†åŒ–åˆ—å", use_container_width=True):
            clean_df.columns = [str(col).strip().replace(' ', '_') for col in clean_df.columns]
            st.success("âœ… åˆ—åå·²æ ‡å‡†åŒ–")
            st.rerun()
    
    with quick_ops[4]:
        if st.button("é¢„è§ˆæ•°æ®", use_container_width=True):
            with st.expander("æ•°æ®é¢„è§ˆ", expanded=True):
                st.dataframe(clean_df.head(20), use_container_width=True)
    
    # é«˜çº§æ¸…æ´—é€‰é¡¹
    st.markdown("### ğŸ”§ é«˜çº§æ¸…æ´—é€‰é¡¹")
    
    tab1, tab2, tab3, tab4 = st.tabs(["åˆ—æ“ä½œ", "è¡Œæ“ä½œ", "æ•°æ®ç±»å‹", "æ‰¹é‡å¤„ç†"])
    
    with tab1:
        col_operation = st.selectbox(
            "é€‰æ‹©åˆ—æ“ä½œ",
            ["é‡å‘½ååˆ—", "åˆ é™¤åˆ—", "ç§»åŠ¨åˆ—", "æå–åˆ—"]
        )
        
        if col_operation == "é‡å‘½ååˆ—":
            col_to_rename = st.selectbox("é€‰æ‹©è¦é‡å‘½åçš„åˆ—", clean_df.columns)
            new_name = st.text_input("æ–°åˆ—å", value=col_to_rename)
            if st.button("æ‰§è¡Œé‡å‘½å", key="rename_col"):
                clean_df = clean_df.rename(columns={col_to_rename: new_name})
                st.success(f"âœ… å·²é‡å‘½åä¸º: {new_name}")
                st.rerun()
        
        elif col_operation == "åˆ é™¤åˆ—":
            cols_to_drop = st.multiselect("é€‰æ‹©è¦åˆ é™¤çš„åˆ—", clean_df.columns)
            if cols_to_drop and st.button("æ‰§è¡Œåˆ é™¤", key="drop_cols"):
                clean_df = clean_df.drop(columns=cols_to_drop)
                st.success(f"âœ… å·²åˆ é™¤ {len(cols_to_drop)} åˆ—")
                st.rerun()
    
    with tab2:
        row_operation = st.selectbox(
            "é€‰æ‹©è¡Œæ“ä½œ",
            ["åˆ é™¤ç©ºè¡Œ", "åˆ é™¤é‡å¤", "ç­›é€‰è¡Œ", "æ’åº"]
        )
        
        if row_operation == "æ’åº":
            sort_col = st.selectbox("æŒ‰å“ªåˆ—æ’åº", clean_df.columns)
            sort_asc = st.checkbox("å‡åºæ’åº", value=True)
            if st.button("æ‰§è¡Œæ’åº", key="sort_rows"):
                clean_df = clean_df.sort_values(by=sort_col, ascending=sort_asc)
                st.success("âœ… æ’åºå®Œæˆ")
                st.rerun()
    
    with tab3:
        dtype_operation = st.selectbox(
            "æ•°æ®ç±»å‹è½¬æ¢",
            ["è‡ªåŠ¨æ£€æµ‹ç±»å‹", "è½¬æ¢ä¸ºå­—ç¬¦ä¸²", "è½¬æ¢ä¸ºæ•°å€¼", "è½¬æ¢ä¸ºæ—¥æœŸ"]
        )
        
        col_to_convert = st.selectbox("é€‰æ‹©è¦è½¬æ¢çš„åˆ—", clean_df.columns)
        
        if st.button("æ‰§è¡Œè½¬æ¢", key="convert_dtype"):
            if dtype_operation == "è‡ªåŠ¨æ£€æµ‹ç±»å‹":
                clean_df[col_to_convert] = pd.to_numeric(
                    clean_df[col_to_convert], errors='ignore'
                )
            elif dtype_operation == "è½¬æ¢ä¸ºå­—ç¬¦ä¸²":
                clean_df[col_to_convert] = clean_df[col_to_convert].astype(str)
            elif dtype_operation == "è½¬æ¢ä¸ºæ•°å€¼":
                clean_df[col_to_convert] = pd.to_numeric(
                    clean_df[col_to_convert], errors='coerce'
                )
            elif dtype_operation == "è½¬æ¢ä¸ºæ—¥æœŸ":
                clean_df[col_to_convert] = pd.to_datetime(
                    clean_df[col_to_convert], errors='coerce'
                )
            
            st.success(f"âœ… ç±»å‹è½¬æ¢å®Œæˆ")
            st.rerun()
    
    # æœ€ç»ˆç»“æœå’Œä¸‹è½½
    st.markdown("### ğŸ’¾ æœ€ç»ˆç»“æœ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        with st.expander("æ¸…æ´—åæ•°æ®é¢„è§ˆ", expanded=True):
            st.dataframe(clean_df.head(30), use_container_width=True)
    
    with col2:
        # ä¿å­˜åˆ°ç®¡é“
        if st.button("ğŸ’¾ ä¿å­˜åˆ°ç®¡é“", use_container_width=True):
            st.session_state.data_pipeline['æ¸…æ´—ç»“æœ'] = {
                'data': clean_df,
                'shape': clean_df.shape,
                'memory_mb': clean_df.memory_usage(deep=True).sum() / 1024 / 1024,
                'timestamp': pd.Timestamp.now()
            }
            st.success("âœ… å·²ä¿å­˜åˆ°æ•°æ®ç®¡é“")
        
        # ä¸‹è½½æŒ‰é’®
        output = BytesIO()
        clean_df.to_excel(output, index=False)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½æ¸…æ´—ç»“æœ",
            data=output.getvalue(),
            file_name="æ¸…æ´—ç»“æœ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )

# ============================================
# é¡µè„š
# ============================================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9rem;'>
    ğŸš€ ä¼˜åŒ–ç‰ˆæ•°æ®å¤„ç†å·¥å…· | æ”¯æŒæ•°æ®ç®¡é“ä¼ é€’ | è‡ªåŠ¨ç±»å‹è½¬æ¢ | å¿«é€Ÿå¤„ç†
</div>
""", unsafe_allow_html=True)
